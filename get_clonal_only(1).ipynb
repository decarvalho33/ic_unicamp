{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_Hobb94wPSv"
      },
      "source": [
        "Agora vamos fazer a mineração de um texto e extrair palavras chaves:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "7cAQcswIWrT4"
      },
      "outputs": [],
      "source": [
        "#urls vão de 30102426 a 30102644, são 219 bioprojects\n",
        "\n",
        "biosample_len = 12\n",
        "SRA_len = 11\n",
        "pbioproject_len = 11\n",
        "\n",
        "start_nURL = 30102426\n",
        "end_nURL = 30102644\n",
        "\n",
        "urls = []\n",
        "\n",
        "while (start_nURL < (end_nURL+1)):\n",
        "  urls.append('https://www.ncbi.nlm.nih.gov/biosample/'+str(start_nURL))\n",
        "  start_nURL += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0dsM3Dzy2A_"
      },
      "source": [
        "Importamos algumas bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "RIrOkzW0g5O8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "DJkiYbdCXs8q"
      },
      "outputs": [],
      "source": [
        "all_text = ['']\n",
        "\n",
        "text = requests.get(urls[0]).content.decode('utf-8')\n",
        "\n",
        "i = 0\n",
        "for url in urls:\n",
        "    text = requests.get(url).content.decode('utf-8')\n",
        "    all_text[i] = text\n",
        "    i += 1\n",
        "\n",
        "print(all_text[i])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(text)\n",
        "\n",
        "biosample_index = text.index(\"BioSample: \")\n",
        "pbioproject_index = text.index(\"href=\\\"/bioproject/\")\n",
        "sra_index = text.index(\"SRA: \")\n",
        "\n",
        "biosample = text[(biosample_index+11):(biosample_index+11+biosample_len)]\n",
        "pbioproject = text[(pbioproject_index+26):(pbioproject_index+26+pbioproject_len+5)]\n",
        "SRA = text[(sra_index+5):(sra_index+5+SRA_len+5)]\n",
        "\n",
        "print(\"biosample =\", biosample)\n",
        "print(\"pbioproject =\", pbioproject)\n",
        "print(\"SRA =\", SRA)\n"
      ],
      "metadata": {
        "id": "ziXLJoCj9R56",
        "outputId": "18f34f42-d1d5-466e-dfd0-44e1423d18a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "biosample = SAMN30102426\n",
            "pbioproject = PRJNA865262</a> \n",
            "SRA = SRS14396699</dd>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvMwme7S0wH1"
      },
      "source": [
        "Convertemos a linguagem de marcação html em um texto simples usando o objeto HTMLParser. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LUQaJ953X8fm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2141e94b-4ed8-47c6-cc63-f5b2b2fdede5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "não tem\n"
          ]
        }
      ],
      "source": [
        "from html.parser import HTMLParser\n",
        "\n",
        "class MyHTMLParser(HTMLParser):\n",
        "    script = False\n",
        "    res = \"\"\n",
        "    def handle_starttag(self, tag, attrs):\n",
        "        if tag.lower() in [\"script\",\"style\"]:\n",
        "            self.script = True\n",
        "    def handle_endtag(self, tag):\n",
        "        if tag.lower() in [\"script\",\"style\"]:\n",
        "            self.script = False\n",
        "    def handle_data(self, data):\n",
        "        if str.strip(data)==\"\" or self.script:\n",
        "            return\n",
        "        self.res += ' '+data.replace('[ edit ]','')\n",
        "\n",
        "parser = MyHTMLParser()\n",
        "parser.feed(text)\n",
        "text = parser.res\n",
        "\n",
        "# start_index = text.index(\"Abstract\")\n",
        "# end_index = text.index(\"References\")\n",
        "# text = text[(start_index+8):end_index]\n",
        "\n",
        "#print(text)             \n",
        "\n",
        "if (\"clonal isolate\" in text):\n",
        "  print(\"tem\")\n",
        "else:\n",
        "  print(\"não tem\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}